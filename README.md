# Домашнее задание к занятию "13.Системы мониторинга" Шарапат Виктор

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?
#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?
#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?
#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios
#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

## Дополнительное задание (со звездочкой*) - необязательно к выполнению

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)
    
    ---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

### Решение 

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

### 1. **Метрики HTTP-запросов:**
   - **Количество запросов (Requests per second):** Позволяет оценить нагрузку на сервер и обнаружить пиковые нагрузки.
   - **Время ответа (Response time):** Высокое время ответа может указывать на проблемы с производительностью или задержки в вычислениях.
   - **Коды ответов HTTP (HTTP status codes):** Позволяют отслеживать количество успешных (2xx), перенаправлений (3xx), ошибок клиента (4xx) и ошибок сервера (5xx) запросов.

### 2. **Метрики нагрузки на ЦПУ:**
   - **Использование ЦПУ (CPU usage):** Важно для мониторинга загрузки процессора, особенно учитывая, что вычисления загружают ЦПУ. 
   - **Количество процессов/потоков:** Позволяет оценить, сколько процессов или потоков запущено на сервере.

### 3. **Метрики дискового ввода/вывода:**
   - **Загрузка диска (Disk I/O):** Учитывая, что отчеты сохраняются на диск, важно отслеживать загрузку диска, чтобы избежать проблем с записью/чтением данных.
   - **Свободное место на диске:** Важно для мониторинга, чтобы избежать ситуаций, когда на диске не остается свободного места для сохранения отчетов.

### 4. **Метрики памяти:**
   - **Использование памяти (Memory usage):** Важно для мониторинга, чтобы избежать утечек памяти или ситуаций, когда приложение потребляет слишком много памяти, что может привести к сбоям.
   - **Свободная память (Free memory):** Позволяет оценить, сколько памяти доступно для работы приложения.

### 5. **Метрики сети:**
   - **Скорость передачи данных (Network throughput):** Позволяет оценить, насколько интенсивно используется сеть, что может быть важно для больших объемов данных или высокой нагрузки.
   - **Количество ошибок сети (Network errors):** Позволяет отслеживать проблемы с сетевым подключением, которые могут повлиять на доступность платформы.

### 6. **Метрики доступности:**
   - **Доступность сервиса (Service availability):** Важно для мониторинга, чтобы убедиться, что платформа доступна для пользователей.
   - **Время простоя (Downtime):** Позволяет оценить, сколько времени сервис был недоступен.

---

2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?

Для того чтобы менеджер продукта мог легко интерпретировать метрики и понимать, насколько платформа выполняет свои обязанности перед клиентами и какое качество обслуживания, можно предложить следующие подходы:

### 1. **Бизнес-метрики:**
   - **Количество успешно обработанных запросов (Successful requests):** Показывает, сколько запросов было успешно обработано платформой. Это прямой показатель того, насколько платформа выполняет свои обязанности перед клиентами.
   - **Количество ошибок при обработке запросов (Failed requests):** Показывает, сколько запросов завершилось с ошибками. Высокий процент ошибок может указывать на проблемы с качеством обслуживания.
   - **Среднее время выполнения запроса (Average request processing time):** Показывает, сколько в среднем занимает обработка одного запроса. Низкое время обработки указывает на высокое качество обслуживания.

### 2. **Метрики доступности и SLA:**
   - **Доступность сервиса (Service availability):** Показывает, насколько часто платформа была доступна для клиентов. Это ключевая метрика для оценки выполнения SLA (Соглашения об уровне обслуживания).
   - **Время простоя (Downtime):** Показывает, сколько времени платформа была недоступна. Это также важный показатель для оценки выполнения SLA.
   - **Количество инцидентов (Incidents):** Показывает, сколько раз платформа сталкивалась с проблемами, которые влияли на доступность или производительность.

### 3. **Метрики пользовательского опыта:**
   - **Уровень удовлетворенности клиентов (Customer satisfaction rate):** Если у вас есть возможность собирать обратную связь от клиентов, это может быть полезным показателем качества обслуживания.
   - **Количество жалоб от клиентов (Customer complaints):** Показывает, сколько жалоб было получено от клиентов. Высокое количество жалоб может указывать на проблемы с качеством обслуживания.

### 4. **Метрики производительности:**
   - **Среднее время ответа (Average response time):** Показывает, сколько в среднем занимает время ответа на запросы. Низкое время ответа указывает на высокую производительность и качество обслуживания.
   - **Пиковое время ответа (Peak response time):** Показывает максимальное время ответа на запросы. Это важно для оценки того, как платформа справляется с пиковой нагрузкой.

### 5. **Метрики ресурсов (в упрощенном виде):**
   - **Использование ресурсов (Resource usage):** Можно представить в виде процента загрузки ЦПУ, памяти и диска. Например, "ЦПУ загружен на 70%", "Память используется на 60%", "Диск заполнен на 50%". Это позволит менеджеру продукта легче интерпретировать данные.

### 6. **Отчеты и дашборды:**
   - **Создание дашбордов с бизнес-метриками:** Создайте дашборды, которые будут отображать ключевые бизнес-метрики в удобном для понимания виде. Например, графики, диаграммы и таблицы, которые показывают доступность сервиса, количество успешных и неуспешных запросов, среднее время ответа и т.д.
   - **Ежедневные/еженедельные отчеты:** Предоставляйте менеджеру продукта регулярные отчеты, которые будут содержать ключевые метрики и их изменения за период.

### 7. **Интерпретация технических метрик:**
   - **Предоставление контекста:** Объясните, что означают технические метрики (RAM, inodes, CPUla) в контексте бизнес-логики. Например, "Высокое использование ЦПУ может привести к замедлению обработки запросов, что повлияет на время ответа и удовлетворенность клиентов".
   - **Создание алиасов:** Используйте более понятные названия для технических метрик, например, "Загрузка процессора" вместо "CPUla", "Использование памяти" вместо "RAM".

---

#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?

В ситуации, когда финансирование на построение системы сбора логов не выделено, можно предпринять несколько решений, которые позволят разработчикам получать информацию об ошибках приложений без значительных затрат. Вот несколько вариантов:

### 1. **Использование бесплатных/открытых инструментов:**
   - **ELK Stack (Elasticsearch, Logstash, Kibana):** Хотя ELK Stack может потребовать некоторых ресурсов для развертывания, его бесплатные версии (Elasticsearch и Kibana) могут быть использованы для сбора и визуализации логов. Logstash можно заменить на более легковесные инструменты, такие как Fluentd или Filebeat.
   - **Fluentd + Elasticsearch + Kibana:** Fluentd — это легковесный инструмент для сбора логов, который может быть использован вместо Logstash.
   - **Prometheus + Grafana:** Если вам нужно собирать метрики и логи, Prometheus может быть использован для сбора метрик, а Grafana — для визуализации. Prometheus также может собирать логи, используя Promtail и Loki.
   - **Sentry:** Sentry — это инструмент для сбора ошибок, который может быть развернут на собственных серверах. Он предоставляет бесплатный план для небольших проектов.

### 2. **Локальное хранение и анализ логов:**
   - **Локальные файлы:** Разработчики могут настроить приложения на запись логов в локальные файлы. Затем эти файлы можно просматривать и анализировать с помощью стандартных инструментов, таких как `grep`, `awk`, `tail`, и т.д.
   - **Cron-задачи для отправки логов:** Настроить cron-задачи для периодической отправки логов на почту или в Slack-канал разработчиков.

### 3. **Самостоятельное развертывание простых решений:**
   - **Самостоятельное развертывание ELK/EFK:** Если у вас есть возможность использовать небольшие серверы, можно развернуть ELK (Elasticsearch, Logstash, Kibana) или EFK (Elasticsearch, Fluentd, Kibana) стек самостоятельно.
   - **Использование SQLite для хранения логов:** Можно настроить приложение на запись логов в SQLite базу данных, а затем использовать простые скрипты для анализа логов.

### 4. **Интеграция с CI/CD:**
   - **Интеграция с CI/CD системами:** Настроить CI/CD систему для отправки уведомлений о ошибках в процессе сборки и тестирования.
   - **Автоматические тесты:** Настроить автоматические тесты, которые будут отслеживать ошибки и отправлять уведомления разработчикам.

### 5. **Использование инструментов для мониторинга:**
   - **Prometheus + Alertmanager:** Prometheus может быть использован для сбора метрик, а Alertmanager — для отправки уведомлений о ошибках.
   - **Zabbix:** Zabbix — это инструмент для мониторинга, который может быть использован для сбора логов и отправки уведомлений.

---

#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
#

Ошибка в формуле заключается в том, что она не учитывает все коды ответов, которые могут влиять на SLA. В частности, коды ответов 3xx (перенаправления) и 1xx (информационные) также должны быть учтены в общем количестве запросов. 

### Правильная формула для расчета SLA:
SLA = (summ_2xx_requests + summ_3xx_requests + summ_1xx_requests) / summ_all_requests

### Почему это важно:
- **Коды 3xx (перенаправления):** Эти коды не являются ошибками и не должны снижать SLA. Они просто указывают на то, что запрос был перенаправлен на другой ресурс.
- **Коды 1xx (информационные):** Эти коды также не являются ошибками и не должны снижать SLA. Они предоставляют предварительную информацию о состоянии запроса.

### Пример:
Предположим, у нас есть следующие данные за период:
- 2xx запросов: 700
- 3xx запросов: 200
- 1xx запросов: 100
- Всего запросов: 1000

Формула:
SLA = (700 + 200 + 100) / 1000 = 1000 / 1000 = 1.0 (или 100%)

### Вывод:

Ошибка заключалась в том, что вы не учитывали коды ответов 3xx и 1xx в общем количестве запросов. Правильная формула должна учитывать все коды ответов, которые не являются ошибками, чтобы корректно рассчитать SLA.

---

5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#

Системы мониторинга могут быть разделены на два основных типа: **pull-системы** и **push-системы**. Каждый из этих подходов имеет свои преимущества и недостатки. Давайте рассмотрим их подробнее.

### Pull-системы мониторинга

**Плюсы:**

1. **Контроль централизованного сервера:**
   - Централизованный сервер (например, Prometheus) контролирует, какие данные собираются и когда. 

2. **Простая отладка:**
   - Легко отследить, откуда поступают данные, так как сервер явно запрашивает их с каждого узла. 

3. **Безопасность:**
   - Меньше рисков связанных с безопасностью, так как данные передаются только по запросу сервера. 

4. **Стабильность:**
   - Сервер может контролировать частоту запросов и объем данных, что помогает избежать перегрузки сети и серверов.

5. **Простота масштабирования:**
   - Легко добавлять новые узлы в систему, так как сервер может автоматически обнаруживать их и начинать сбор данных.

**Минусы:**

1. **Зависимость от центрального сервера:**
   - Если центральный сервер выходит из строя, сбор данных прекращается. 

2. **Сложность в настройке:**
   - Требуется настройка и конфигурация центрального сервера для каждого узла, что может быть сложным в больших и динамичных средах.

3. **Проблемы с сетью:**
   - Если узлы находятся за NAT или в разных сетях, может быть сложно настроить pull-систему.

### Push-системы мониторинга

**Плюсы:**

1. **Простота настройки:**
   - Узлы самостоятельно отправляют данные на центральный сервер, что упрощает настройку и масштабирование.

2. **Гибкость:**
   - Узлы могут отправлять данные с разной частотой и в разное время, что позволяет гибко настраивать сбор данных.

3. **Независимость от центрального сервера:**
   - Если центральный сервер выходит из строя, узлы могут продолжать отправлять данные, и они будут сохранены локально до восстановления сервера.

4. **Подходит для динамичных сред:**
   - Хорошо подходит для сред, где узлы часто добавляются и удаляются, так как они могут самостоятельно регистрироваться на сервере.

5. **Простота интеграции:**
   - Легко интегрировать с различными системами и инструментами, так как данные могут быть отправлены в разные системы мониторинга.

**Минусы:**

1. **Риски безопасности:**
   - Узлы активно отправляют данные на сервер, что может создать риски безопасности, если данные не защищены должным образом.

2. **Перегрузка сети:**
   - Если узлы отправляют данные слишком часто или в больших объемах, это может привести к перегрузке сети и серверов.

3. **Проблемы с отладкой:**
   - Сложно отследить, откуда поступают данные, так как узлы сами инициируют отправку. Это может усложнить отладку и поиск проблем.

4. **Проблемы с надежностью:**
   - Если узлы не настроены правильно, они могут не отправлять данные или отправлять их некорректно, что может привести к потере данных и проблемам с мониторингом.

### Вывод:

**Pull-системы** лучше подходят для стабильных и контролируемых сред, где важна безопасность и контроль над сбором данных. 

**Push-системы** лучше подходят для динамичных и распределенных сред, где узлы часто добавляются и удаляются. Они обеспечивают гибкость и простоту настройки, но требуют внимания к безопасности и управлению нагрузкой.

6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios
#

    - Prometheus - Pull
    - TICK - Гибридные
    - Zabbix - Гибридные
    - VictoriaMetrics - Гибридные
    - Nagios - Pull

- **Prometheus** и **Nagios** используют преимущественно pull-модель. 
- **TICK**, **Zabbix** и **VictoriaMetrics** предоставляют гибкость в выборе модели сбора данных, что делает их гибридными системами.

Выбор модели зависит от конкретных требований и особенностей вашей инфраструктуры.

#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`

![Screenshot_2](https://github.com/user-attachments/assets/9b311521-a055-4077-84e5-8f1dbcd37971)

![Screenshot_1](https://github.com/user-attachments/assets/86e0de3d-0576-4e38-b1d2-50ab42f42675)

---

#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#

![Screenshot_3](https://github.com/user-attachments/assets/211a5bbf-8682-4695-951d-44ceee7c5092)

---

9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

![Screenshot_4](https://github.com/user-attachments/assets/89378f8b-9270-4623-80ae-3656c1fe7769)

![Screenshot_5](https://github.com/user-attachments/assets/3352f142-42bf-4017-a02e-2c245179bc25)

![Screenshot_6](https://github.com/user-attachments/assets/a22d3a65-22a1-4ba3-9c13-aba1229d7aed)

---




